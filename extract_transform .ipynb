{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(directory, fileNames, createSample=False):\n",
    "    \"\"\"\n",
    "    json_to_csv: loops through specified JSON files and converts them to csv files.\n",
    "                 option to also create a sample csv, which uses np.random.seed 9001 to create a sample dataset with 10% of the observations\n",
    "    \n",
    "                 pandas has a read_json function, but returns a 'Trailing data error' when working with these specific files\n",
    "                 \n",
    "                 \n",
    "    Inputs: -directory of JSON files\n",
    "            -list of JSON filenames\n",
    "            -createSample flag\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    jsonData = []\n",
    "\n",
    "    for fileName in fileNames:\n",
    "        with open(directory + fileName,  encoding=\"utf8\") as file:\n",
    "            print('{0} opened'.format(fileName))\n",
    "            for line in file:\n",
    "                #I use an rstrip here because some of the files have trailing blank spaces\n",
    "                jsonData.append(json.loads(line.rstrip()))\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(jsonData)\n",
    "        \n",
    "        csvFileName = fileName[:len(fileName)-5] + '.csv'\n",
    "        \n",
    "        df.to_csv(directory + csvFileName)\n",
    "        print('{0} created'.format(csvFileName))\n",
    "        \n",
    "        \n",
    "        if createSample:\n",
    "            np.random.seed(9001)\n",
    "            msk = np.random.rand(len(df)) <= 0.1\n",
    "            sample = df[msk]\n",
    "            \n",
    "            csvSampleFileName = fileName[:len(fileName)-5] + '_sample.csv'\n",
    "            \n",
    "            sample.to_csv(directory + csvSampleFileName)\n",
    "            print('{0} created'.format(csvSampleFileName))\n",
    "        \n",
    "    print('This function took {} minutes to run'.format((time.time()-start)/60))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user.json opened\n",
      "user.csv created\n",
      "user_sample.csv created\n",
      "business.json opened\n",
      "business.csv created\n",
      "business_sample.csv created\n",
      "review.json opened\n"
     ]
    }
   ],
   "source": [
    "fileNameList = ['user.json',\n",
    "                'business.json']\n",
    "\n",
    "json_to_csv('data/', fileNameList, createSample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping only \"restaurant\" business data and other associated data on users and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ftres_with_nan(df):\n",
    "    all_nan = df.columns[df.isnull().all()].tolist()\n",
    "    some_nan = df.columns[df.isnull().any()].tolist()\n",
    "    print(\"All NaN Features: \", len(all_nan), all_nan, \"Some NaN Features: \", len(some_nan), some_nan)\n",
    "    return all_nan, some_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'attributes', 'average_stars', 'business_id', 'categories',\n",
       "       'city', 'compliment_cool', 'compliment_cute', 'compliment_funny',\n",
       "       'compliment_hot', 'compliment_list', 'compliment_more',\n",
       "       'compliment_note', 'compliment_photos', 'compliment_plain',\n",
       "       'compliment_profile', 'compliment_writer', 'cool', 'elite', 'fans',\n",
       "       'friends', 'funny', 'hours', 'is_open', 'latitude', 'longitude', 'name',\n",
       "       'postal_code', 'review_count', 'stars', 'state', 'useful', 'user_id',\n",
       "       'yelping_since'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All NaN Features:  12 ['address', 'attributes', 'business_id', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'postal_code', 'stars', 'state'] Some NaN Features:  13 ['address', 'attributes', 'business_id', 'categories', 'city', 'elite', 'hours', 'is_open', 'latitude', 'longitude', 'postal_code', 'stars', 'state']\n"
     ]
    }
   ],
   "source": [
    "business = pd.read_csv('data/business.csv',encoding = \"ISO-8859-1\",index_col=0, nrows = 10000)\n",
    "all_nan, some_nan = find_ftres_with_nan(business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "5      NaN\n",
       "6      NaN\n",
       "7      NaN\n",
       "8      NaN\n",
       "9      NaN\n",
       "10     NaN\n",
       "11     NaN\n",
       "12     NaN\n",
       "13     NaN\n",
       "14     NaN\n",
       "15     NaN\n",
       "16     NaN\n",
       "17     NaN\n",
       "18     NaN\n",
       "19     NaN\n",
       "20     NaN\n",
       "21     NaN\n",
       "22     NaN\n",
       "23     NaN\n",
       "24     NaN\n",
       "25     NaN\n",
       "26     NaN\n",
       "27     NaN\n",
       "28     NaN\n",
       "29     NaN\n",
       "        ..\n",
       "9970   NaN\n",
       "9971   NaN\n",
       "9972   NaN\n",
       "9973   NaN\n",
       "9974   NaN\n",
       "9975   NaN\n",
       "9976   NaN\n",
       "9977   NaN\n",
       "9978   NaN\n",
       "9979   NaN\n",
       "9980   NaN\n",
       "9981   NaN\n",
       "9982   NaN\n",
       "9983   NaN\n",
       "9984   NaN\n",
       "9985   NaN\n",
       "9986   NaN\n",
       "9987   NaN\n",
       "9988   NaN\n",
       "9989   NaN\n",
       "9990   NaN\n",
       "9991   NaN\n",
       "9992   NaN\n",
       "9993   NaN\n",
       "9994   NaN\n",
       "9995   NaN\n",
       "9996   NaN\n",
       "9997   NaN\n",
       "9998   NaN\n",
       "9999   NaN\n",
       "Name: categories, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-556ba597dccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a mask for restaurants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask_restaurants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbusiness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restaurants'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create a mask for food\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmask_food\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbusiness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Food'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5061\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[1;32m   1819\u001b[0m                                  \u001b[0;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                                  \"pandas\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "# create a mask for restaurants\n",
    "mask_restaurants = business['categories'].str.contains('Restaurants')\n",
    "\n",
    "# create a mask for food\n",
    "mask_food = business['categories'].str.contains('Food')\n",
    "\n",
    "# apply both masks\n",
    "restaurants_and_food = business[mask_restaurants & mask_food]\n",
    "\n",
    "# number of businesses that have food and restaurant in their category\n",
    "restaurants_and_food['categories'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after taking buisnesses that have both food and restaurant in their categories, there are still irrelevant business categories in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Specialty Food, Restaurants, Dim Sum, Imported Food, Food, Chinese, Ethnic Food, Seafood'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example row\n",
    "restaurants_and_food.head(1)['categories'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryDF = restaurants_and_food['categories'].apply(lambda x: x[1:-1].split(',')).apply(pd.Series)\n",
    "uniqueCategories = pd.DataFrame(categoryDF.stack().str.strip().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoriesToRemove = ['Grocery','Drugstores','Convenience Stores','Beauty & Spas','Photography Stores & Services',\n",
    "                      'Cosmetics & Beauty Supply','Discount Store','Fashion','Department Stores','Gas Stations',\n",
    "                      'Automotive','Music & Video','Event Planning & Services','Mobile Phones','Health & Medical',\n",
    "                      'Weight Loss Centers','Home & Garden','Kitchen & Bath','Jewelry',\"Children's Clothing\",\n",
    "                      'Accessories','Home Decor','Bus Tours','Auto Glass Services','Auto Detailing',\n",
    "                      'Oil Change Stations', 'Auto Repair','Body Shops','Car Window Tinting','Car Wash',\n",
    "                      'Gluten-Free','Fitness & Instruction','Nurseries & Gardening','Wedding Planning',\n",
    "                      'Embroidery & Crochet','Dance Schools','Performing Arts',\n",
    "                      'Wholesale Stores','Tobacco Shops','Nutritionists','Hobby Shops','Pet Services',\n",
    "                      'Electronics','Plumbing','Gyms','Yoga','Walking Tours','Toy Stores','Pet Stores',\n",
    "                      'Pet Groomers','Vape Shops','Head Shops',\n",
    "                      'Souvenir Shops','Pharmacy','Appliances & Repair','Wholesalers','Party Equipment Rentals',\n",
    "                      'Tattoo','Funeral Services & Cemeteries','Sporting Goods','Dog Walkers',\n",
    "                      'Pet Boarding/Pet Sitting','Scavenger Hunts','Contractors','Trainers', \n",
    "                      'Customized Merchandise', 'Dry Cleaning & Laundry', 'Art Galleries'\n",
    "                      'Tax Law', 'Bankruptcy Law', 'Tax Services', 'Estate Planning Law', \n",
    "                      'Business Consulting', 'Lawyers', 'Pet Adoption', 'Escape Games', \n",
    "                      'Animal Shelters', 'Commercial Real Estate', 'Real Estate Agents', \n",
    "                      'Real Estate Services', 'Home Inspectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df = restaurants_and_food[~restaurants_and_food['categories'].str.contains('|'.join(categoriesToRemove))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All NaN Features:  20 ['average_stars', 'compliment_cool', 'compliment_cute', 'compliment_funny', 'compliment_hot', 'compliment_list', 'compliment_more', 'compliment_note', 'compliment_photos', 'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'elite', 'fans', 'friends', 'funny', 'useful', 'user_id', 'yelping_since'] Some NaN Features:  24 ['address', 'attributes', 'average_stars', 'compliment_cool', 'compliment_cute', 'compliment_funny', 'compliment_hot', 'compliment_list', 'compliment_more', 'compliment_note', 'compliment_photos', 'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'elite', 'fans', 'friends', 'funny', 'hours', 'postal_code', 'useful', 'user_id', 'yelping_since']\n"
     ]
    }
   ],
   "source": [
    "restaurants_df.to_csv('data/restaurants.csv')\n",
    "restaurants_df = pd.read_csv('data/restaurants.csv', encoding='ISO-8859-1', index_col=0)\n",
    "all_nan, some_nan = find_ftres_with_nan(restaurants_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding business attributes & categories\n",
    "After cleaning the business dataset, we expanded the attributes into boolean features. The attributes were a collection of a string of a dictionary. We evaluated this string as a dictionary and applied pd.Series across the result, which expanded this dictionary into multiple Boolean columns, as well as a few more dictionary columns. All remaining dictionary columns were manipulated in the same manner, leaving us ~70 Boolean columns. The business dataset also had a variable, categories, that was a string of a list. We expanded this list into separate columns for each category. Lastly, we then reduced our user dataset by filtering to users that existed in the reduced review dataset. The following functions were used for this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create_attributes\n",
    "\n",
    "# #takes a dataframe as an input, as well as a list of columns that are dictionaries\n",
    "# #takes each column that is a dictionary, and expands it into a series of dummy columns\n",
    "\n",
    "# def create_attributes(df, dictList):\n",
    "    \n",
    "#     for dictionaryColumn in dictList:\n",
    "        \n",
    "#         #the attributes column is a string of dictionaries, so one extra step is taken to convert\n",
    "#         if dictionaryColumn == 'attributes':\n",
    "#             expandedColumns = df[dictionaryColumn].map(eval).apply(pd.Series)\n",
    "#         else:\n",
    "#             expandedColumns = df[dictionaryColumn].apply(pd.Series)\n",
    "        \n",
    "#         df = pd.concat([df.drop(dictionaryColumn,axis=1), \n",
    "#                    expandedColumns]\n",
    "#                   ,axis=1)\n",
    "        \n",
    "#         #df.fillna(value='{}',inplace=True)\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expand_categories(df, cat_var, key):\n",
    "#     all_cats = df[cat_var].str.cat(sep=', ')\n",
    "#     all_cats = all_cats.replace('[', '')\n",
    "#     all_cats = all_cats.replace(']', '')\n",
    "#     all_cats = all_cats.replace(\"\\'\",\"\")\n",
    "#     all_cats = all_cats.replace('\"','')\n",
    "#     all_cats_list = all_cats.split(', ')\n",
    "#     unique_cats = list(set(all_cats_list))\n",
    "#     unique_cats.remove('Restaurants')\n",
    "#     unique_cats.remove('Food')\n",
    "#     df_cats = pd.DataFrame(index=df[key], columns=unique_cats, data=False)\n",
    "#     df_out = df.merge(df_cats, how='left', left_on=key, right_index=True)\n",
    "#     for cat in unique_cats:\n",
    "#         df_out[cat] = df_out[cat_var].str.contains(cat)\n",
    "#     return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictList = ['attributes', 'Ambience', 'BestNights', 'BusinessParking','Music','GoodForMeal']\n",
    "# expanded = create_attributes(restaurants_df[['business_id','attributes']], dictList)\n",
    "# dropColumns = expanded.columns.get_loc(0)\n",
    "# keepColumns = list(compress(expanded.columns, ~dropColumns))\n",
    "# expanded = expanded[keepColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1637139</th>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'GoodForMe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      address  \\\n",
       "1637139  30 Eglinton Avenue W   \n",
       "\n",
       "                                                attributes  average_stars  \\\n",
       "1637139  {'RestaurantsReservations': 'True', 'GoodForMe...            NaN   \n",
       "\n",
       "                    business_id  \\\n",
       "1637139  QXAEGFB4oINsVuTFxEYKFQ   \n",
       "\n",
       "                                                categories         city  \\\n",
       "1637139  Specialty Food, Restaurants, Dim Sum, Imported...  Mississauga   \n",
       "\n",
       "         compliment_cool  compliment_cute  compliment_funny  compliment_hot  \\\n",
       "1637139              NaN              NaN               NaN             NaN   \n",
       "\n",
       "         ...   latitude  longitude                        name  postal_code  \\\n",
       "1637139  ...  43.605499 -79.652289  Emerald Chinese Restaurant      L5R 3E7   \n",
       "\n",
       "         review_count  stars  state  useful  user_id  yelping_since  \n",
       "1637139           128    2.5     ON     NaN      NaN            NaN  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_review(df, business_list):\n",
    "    \n",
    "#     #drop columns where business_id or user_id is null\n",
    "#     df.dropna(subset=['business_id','user_id'], how='any',inplace=True)\n",
    "    \n",
    "#     #restrict to businesses that are restaurants\n",
    "#     df = df[df['business_id'].isin(business_list)]\n",
    "    \n",
    "#     #only keep user_id's with more than one review\n",
    "#     df = df[df.groupby('user_id').user_id.transform(len) > 1]\n",
    "    \n",
    "#     #verify this worked by taking the minimum amount of user_id counts\n",
    "#     print('The minimum amount of reviews per user is {}'\n",
    "#           .format(np.min(df.groupby('user_id')['business_id'].count())))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review = pd.read_csv('data/review.csv',encoding = \"ISO-8859-1\",index_col=0)\n",
    "# restaurant_reviews = reduce_review(review, restaurants['business_id']) #create dataframe\n",
    "# _, _ = find_ftres_with_nan(restaurant_reviews) #report if there are null values\n",
    "\n",
    "# restaurant_reviews['review_date'] = pd.to_datetime(restaurant_reviews['date'])\n",
    "# restaurant_reviews['review_year'] = restaurant_reviews['review_date'].dt.year\n",
    "# restaurant_reviews['review_month'] = restaurant_reviews['review_date'].dt.month\n",
    "# restaurant_reviews['review_weekday'] = restaurant_reviews['review_date'].dt.weekday_name\n",
    "\n",
    "# rename_cols = {'cool': 'review_cool','funny':'review_funny','stars':'review_stars','useful':'review_useful'}\n",
    "# restaurant_reviews.rename(columns=rename_cols, inplace=True)\n",
    "# review_cols_to_drop = ['text', 'review_date', 'date']\n",
    "# restaurant_reviews.drop(review_cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant_reviews.to_csv('data/restaurant_reviews_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('data/user.csv',encoding = \"ISO-8859-1\",index_col=0)\n",
    "users_w_reviews = users_df[users_df['user_id'].isin(restaurant_reviews['user_id'])].copy()\n",
    "\n",
    "list_user_vars = ['average_stars', 'compliment_cool', 'compliment_cute', 'compliment_funny', \n",
    "                  'compliment_hot', 'compliment_list', 'compliment_more', 'compliment_note', \n",
    "                  'compliment_photos', 'compliment_plain', 'compliment_profile', \n",
    "                  'compliment_writer', 'cool', 'elite', 'fans', 'friends', 'funny', \n",
    "                  'name', 'review_count', 'useful']\n",
    "vars_to_rename_users = dict(zip(list_user_vars, ['user_' + var for var in list_user_vars]))\n",
    "users_w_reviews = users_w_reviews.rename(columns=vars_to_rename_users)\n",
    "\n",
    "users_w_reviews['yelping_since'] = pd.to_datetime(users_w_reviews['yelping_since'])\n",
    "users_w_reviews['yelping_since'] = users_w_reviews['yelping_since'].dt.year\n",
    "\n",
    "users_w_reviews['user_elite_flag'] = users_w_reviews['user_elite'].apply(len) != 2\n",
    "users_w_reviews['user_friends_flag'] = users_w_reviews['user_friends'].apply(len) != 2\n",
    "\n",
    "users_cols_to_drop = ['user_elite', 'user_friends', 'user_name']\n",
    "users_w_reviews.drop(users_cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "users_w_reviews.to_csv('data/user_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
