{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(directory, fileNames, createSample=False):\n",
    "    \"\"\"\n",
    "    json_to_csv: loops through specified JSON files and converts them to csv files.\n",
    "                 option to also create a sample csv, which uses np.random.seed 9001 to create a sample dataset with 10% of the observations\n",
    "    \n",
    "                 pandas has a read_json function, but returns a 'Trailing data error' when working with these specific files\n",
    "                 \n",
    "                 \n",
    "    Inputs: -directory of JSON files\n",
    "            -list of JSON filenames\n",
    "            -createSample flag\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    jsonData = []\n",
    "\n",
    "    for fileName in fileNames:\n",
    "        with open(directory + fileName,  encoding=\"utf8\") as file:\n",
    "            print('{0} opened'.format(fileName))\n",
    "            for line in file:\n",
    "                #I use an rstrip here because some of the files have trailing blank spaces\n",
    "                jsonData.append(json.loads(line.rstrip()))\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(jsonData)\n",
    "        \n",
    "        csvFileName = fileName[:len(fileName)-5] + '.csv'\n",
    "        \n",
    "        df.to_csv(directory + csvFileName)\n",
    "        print('{0} created'.format(csvFileName))\n",
    "        \n",
    "        \n",
    "        if createSample:\n",
    "            np.random.seed(9001)\n",
    "            msk = np.random.rand(len(df)) <= 0.1\n",
    "            sample = df[msk]\n",
    "            \n",
    "            csvSampleFileName = fileName[:len(fileName)-5] + '_sample.csv'\n",
    "            \n",
    "            sample.to_csv(directory + csvSampleFileName)\n",
    "            print('{0} created'.format(csvSampleFileName))\n",
    "        \n",
    "    print('This function took {} minutes to run'.format((time.time()-start)/60))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileNameList = ['user.json',\n",
    "#                 'business.json', \n",
    "#                 'review.json']\n",
    "\n",
    "# json_to_csv('data/', fileNameList, createSample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_business = pd.read_json('data/business.json',lines=True)\n",
    "\n",
    "# df_business.dropna(inplace=True, subset = ['categories'], axis=0)\n",
    "\n",
    "# df_business.loc[df_business['categories'].str.contains('Restaurants')]\n",
    "\n",
    "# df_business['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_user = pd.read_csv('data/user.csv', nrows = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review =  pd.read_csv('data/review.csv', usecols = ['business_id', 'user_id', 'stars'])\n",
    "\n",
    "\n",
    "\n",
    "# user_cnts = df_review['user_id'].value_counts()\n",
    "# top_users = user_cnts.loc[user_cnts>2].index\n",
    "# df_review = df_review.loc[df_review['user_id'].isin(top_users)]\n",
    "# df_review.to_csv('data/filtered_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_csv('data/filtered_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review\n",
    "\n",
    "# df_review['business_id'].value_counts().clip(lower=0,upper=10).hist()\n",
    "\n",
    "# df_review['user_id'].value_counts().clip(lower=0,upper=10).hist()\n",
    "\n",
    "# df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_matrix(df_review, n_users, n_items):\n",
    "#     matrix = np.zeros((n_users, n_items))\n",
    "    \n",
    "#     for line in df.interlupes():\n",
    "        \n",
    "#         matrix[line[1]-1, line[2]-1] = line [3]\n",
    "        \n",
    "#     return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_df = df_review.pivot(index = 'user_id', columns ='business_id', values = 'stars').fillna(0)\n",
    "# R_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise import SVD\n",
    "# from surprise import Dataset\n",
    "# from surprise import NormalPredictor\n",
    "# from surprise import BaselineOnly\n",
    "# from surprise import KNNBasic\n",
    "# from surprise import Reader\n",
    "# from surprise.model_selection import cross_validate\n",
    "# from surprise import NMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fmap_invmap(ser):\n",
    "    uni_ele = ser.unique()\n",
    "    fmap = {v:i for i, v in enumerate(uni_ele)}\n",
    "    invmap = {i:v for i, v in enumerate(uni_ele)}\n",
    "    return fmap, invmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_review.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_fmap, bus_invmap = build_fmap_invmap(df_review['business_id'])\n",
    "u_fmap, u_invmap = build_fmap_invmap(df_review['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_invmap[\n",
    "    u_fmap[df_review['user_id'][0]]\n",
    "  ], df_review['user_id'][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_invmap[bus_fmap[df_review['business_id'].iloc[20]]], df_review['business_id'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review['business_id'] = df_review['business_id'].map(bus_fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review['user_id'] = df_review['user_id'].map(u_fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_bus = df_review['user_id'].nunique(), df_review['business_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vector_raw = tf.Variable(tf.random_uniform([n_users, n_dim], minval = -1., maxval = 1.))\n",
    "bus_vector_raw = tf.Variable(tf.random_uniform([n_bus, n_dim], minval = -1., maxval = 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vector = tf.tanh(user_vector_raw)\n",
    "bus_vector = tf.tanh(bus_vector_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vector_raw.shape, bus_vector_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users = tf.placeholder(tf.int32, shape=(None))\n",
    "businesses = tf.placeholder(tf.int32, shape=(None))\n",
    "ratings = tf.placeholder(tf.float32, shape=(None))\n",
    "\n",
    "UserSampled = tf.nn.embedding_lookup(user_vector, users)\n",
    "BusinessSampled = tf.nn.embedding_lookup(bus_vector, businesses)\n",
    "UserSampled.set_shape([None, n_dim])\n",
    "BusinessSampled.set_shape([None, n_dim])\n",
    "\n",
    "# input tensors for products, users, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatedaffinitiesraw = tf.reduce_sum(UserSampled * BusinessSampled, 1)\n",
    "estimatedaffinities = tf.sigmoid(estimatedaffinitiesraw)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(estimatedaffinities - ratings))\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate=.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.random.choice(df_review.shape[0], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    rows = np.random.choice(df_review.shape[0], 64)\n",
    "    dfrows = df_review.iloc[rows]\n",
    "    fd = {users:dfrows['user_id'].values,\n",
    "         businesses:dfrows['business_id'].values,\n",
    "         ratings:dfrows['stars'].values}\n",
    "    _, l2loss = sess.run([opt, loss], fd)\n",
    "    if i % 1000 == 0:\n",
    "        print(l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_values, bus_values = sess.run([user_vector, bus_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 115\n",
    "u_invmap[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bname = 'cHdJXLlKNWixBXpDwEGb_A'\n",
    "bid = bus_fmap[bname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle = bus_values[bid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japaneselover = user_values[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(bus_values - japaneselover[None,:]).sum(1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(bus_values - chipotle[None,:]).sum(1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_businesses_to(business = None, user = None, df = None):\n",
    "    if business is not None:\n",
    "        target = bus_values[bus_fmap[business]]\n",
    "    if user is not None:\n",
    "        target = user_values[u_fmap[user]]\n",
    "    if df is None:\n",
    "        df = bus_values\n",
    "    best_restaurants = np.square(df - target[None,:]).sum(1).argsort()\n",
    "    return best_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midtown_japanese_restaurants = bus_values[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_businesses_to(business = 'cHdJXLlKNWixBXpDwEGb_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_businesses_to(user = 'ri7itn7-CdpsaPxTToK5cQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_businesses_to(user = 'ri7itn7-CdpsaPxTToK5cQ', df = midtown_japanese_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df_review[[\n",
    "    'business_id', 'stars', 'user_id']], reader)\n",
    "#data2 = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_factors = 5, n_epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrained = model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = modeltrained.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??modeltrained.compute_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark = []\n",
    "# # Iterate over all algorithms\n",
    "# for algorithm in [NMF()]:\n",
    "#     # Perform cross validation\n",
    "#     results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "#     # Get results & append algorithm name\n",
    "#     tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "#     tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "#     benchmark.append(tmp)\n",
    "    \n",
    "# pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_review.fillna(df_review.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_review.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
